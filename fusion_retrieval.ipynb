{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion Retrieval\n",
    "---\n",
    "## Graph RAG\n",
    "---\n",
    "This notebook is built on top of this [Repository](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oblisk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deepeval\\__init__.py:45: UserWarning: You are using deepeval version 0.21.70, however version 1.1.9 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evaluate_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encode the pdf to vector store and return split document from the step before to create BM25 instance\n",
    "\"\"\"\n",
    "\n",
    "def encode_pdf_and_get_split_documents(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore, cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data and create vectorstore and get the chunked documents\n",
    "\"\"\"\n",
    "path = \"data/Understanding_Climate_Change.pdf\"\n",
    "vectorstore, cleaned_texts = encode_pdf_and_get_split_documents(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a bm25 index for retrieving documents by keywords\n",
    "\"\"\"\n",
    "\n",
    "def create_bm25_index(documents: List[Document]) -> BM25Okapi:\n",
    "    \"\"\"\n",
    "    Create a BM25 index from the given documents.\n",
    "\n",
    "    BM25 (Best Matching 25) is a ranking function used in information retrieval.\n",
    "    It's based on the probabilistic retrieval framework and is an improvement over TF-IDF.\n",
    "\n",
    "    Args:\n",
    "    documents (List[Document]): List of documents to index.\n",
    "\n",
    "    Returns:\n",
    "    BM25Okapi: An index that can be used for BM25 scoring.\n",
    "    \"\"\"\n",
    "    # Tokenize each document by splitting on whitespace\n",
    "    # This is a simple approach and could be improved with more sophisticated tokenization\n",
    "    tokenized_docs = [doc.page_content.split() for doc in documents]\n",
    "    return BM25Okapi(tokenized_docs)\n",
    "\n",
    "bm25 = create_bm25_index(cleaned_texts) # Create BM25 index from the cleaned texts (chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a function that retrieves both semantically and by keyword, normalizes the scores and gets the top k documents\n",
    "\"\"\"\n",
    "\n",
    "def fusion_retrieval(vectorstore, bm25, query: str, k: int = 5, alpha: float = 0.5) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Perform fusion retrieval combining keyword-based (BM25) and vector-based search.\n",
    "\n",
    "    Args:\n",
    "    vectorstore (VectorStore): The vectorstore containing the documents.\n",
    "    bm25 (BM25Okapi): Pre-computed BM25 index.\n",
    "    query (str): The query string.\n",
    "    k (int): The number of documents to retrieve.\n",
    "    alpha (float): The weight for vector search scores (1-alpha will be the weight for BM25 scores).\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: The top k documents based on the combined scores.\n",
    "    \"\"\"\n",
    "    # Step 1: Get all documents from the vectorstore\n",
    "    all_docs = vectorstore.similarity_search(\"\", k=vectorstore.index.ntotal)\n",
    "\n",
    "    # Step 2: Perform BM25 search\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    # Step 3: Perform vector search\n",
    "    vector_results = vectorstore.similarity_search_with_score(query, k=len(all_docs))\n",
    "    \n",
    "    # Step 4: Normalize scores\n",
    "    vector_scores = np.array([score for _, score in vector_results])\n",
    "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores))\n",
    "\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
    "\n",
    "    # Step 5: Combine scores\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores  \n",
    "\n",
    "    # Step 6: Rank documents\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "    \n",
    "    # Step 7: Return top k documents\n",
    "    return [all_docs[i] for i in sorted_indices[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "workshops, and community events. Lifelong learning fosters a culture of con tinuous \n",
      "improvement and adaptability.  \n",
      "Intergenerational Dialogue  \n",
      "Youth Engagement  \n",
      "Engaging youth in climate action is critical for long -term sustainability. Youth bring energy, \n",
      "creativity, and a sense of urgency to climate movements. Providing platforms for youth \n",
      "voices, supporting youth -led initiatives, and involving young people in de cision -making \n",
      "processes are essential for meaningful engagement.  \n",
      "Intergenerational Collaboration  \n",
      "Intergenerational collaboration involves working together across age groups to address \n",
      "climate challenges. This includes mentorship programs, intergenerational projects, and \n",
      "dialogue forums. Sharing knowledge and experiences between generations enhances \n",
      "collective capacity and resilience.\n",
      "\n",
      "\n",
      "Context 2:\n",
      "This vision includes a healthy planet, thriving ecosystems, and equitable societies. Working \n",
      "together towards this vision creates a sense of purpose and motivation . \n",
      "By embracing these principles and taking concerted action, we can address the urgent \n",
      "challenge of climate change and build a sustainable, resilient, and equitable world for all. The \n",
      "path forward requires courage, commitment, and collaboration, but the rewa rds are \n",
      "immenseâ€”a thriving planet and a prosperous future for generations to come.  \n",
      "Chapter 13: Climate Change and Social Justice  \n",
      "Climate Justice  \n",
      "Understanding Climate Justice  \n",
      "Climate justice emphasizes the ethical dimensions of climate change, recognizing that its \n",
      "impacts are not evenly distributed. Vulnerable populations, including low -income \n",
      "communities, indigenous peoples, and marginalized groups, often face the greatest ris ks \n",
      "while contributing the least to greenhouse gas emissions. Climate justice advocates for\n",
      "\n",
      "\n",
      "Context 3:\n",
      "Legacy and Responsibility  \n",
      "Recognizing the responsibility to future generations is a fundamental aspect of climate action. \n",
      "This involves making decisions that protect the environment and ensure a sustainable future. \n",
      "Promoting a sense of stewardship and legacy encourages long -term th inking and \n",
      "commitment.  \n",
      "By continuing to innovate, collaborate, and integrate diverse perspectives, we can address the \n",
      "complex and urgent challenge of climate change. Our collective efforts will determine the \n",
      "health and sustainability of our planet for generations to come. Togeth er, we can create a \n",
      "resilient, equitable, and thriving world.\n",
      "\n",
      "\n",
      "Context 4:\n",
      "Legacy for Future Generations  \n",
      "Our actions today shape the world for future generations. Ensuring a sustainable and resilient \n",
      "planet is our responsibility to future generations. By working together, we can create a legacy \n",
      "of environmental stewardship, social equity, and global solidarit y. \n",
      "Chapter 19: Climate Change and Policy  \n",
      "Policy Development and Implementation  \n",
      "National Climate Policies  \n",
      "Countries around the world are developing and implementing national climate policies to \n",
      "address climate change. These policies set emission reduction targets, promote renewable \n",
      "energy, and support adaptation measures. Effective policy implementation requir es\n",
      "\n",
      "\n",
      "Context 5:\n",
      "goals. Policies should promote synergies between biodiversity conservation and climate \n",
      "action.  \n",
      "Chapter 10: Climate Change and Human Health  \n",
      "Health Impacts  \n",
      "Heat -Related Illnesses  \n",
      "Rising temperatures and more frequent heatwaves increase the risk of heat -related illnesses, \n",
      "such as heat exhaustion and heatstroke. Vulnerable populations, including the elderly, \n",
      "children, and outdoor workers, are particularly at risk. Heat mitigation str ategies, such as \n",
      "cooling centers and public health campaigns, are essential.  \n",
      "Vector -Borne Diseases  \n",
      "Climate change affects the distribution and prevalence of vector -borne diseases, such as \n",
      "malaria, dengue fever, and Lyme disease. Warmer temperatures and changing precipitation \n",
      "patterns can expand the habitats of disease -carrying insects, increasing the ri sk of outbreaks. \n",
      "Integrated pest management and disease surveillance are critical for prevention and control.  \n",
      "Respiratory and Cardiovascular Diseases\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test the Algorithm - Add a Usage Example\n",
    "\"\"\"\n",
    "\n",
    "# Query\n",
    "query = \"What are the impacts of climate change on the environment?\"\n",
    "\n",
    "# Perform fusion retrieval\n",
    "top_docs = fusion_retrieval(vectorstore, bm25, query, k=5, alpha=0.5)\n",
    "docs_content = [doc.page_content for doc in top_docs]\n",
    "show_context(docs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
